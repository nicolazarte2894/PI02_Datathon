## **_PROYECTO INDIVIDUAL 01 - DATA ENGINEER_**

---

## INTRODUCCIN

Hola! Me llamo Nicol谩s Angel Lazarte, les presento mi proyecto individual de Machine Learning realizado durante el Bootcamp de Data Science de SoyHenry.  
El proyecto consiste en desarrollar un an谩lisis en torno a un problema de clasificaci贸n de estad铆as cortas o largas en pacientes Hospitalizados. Dicho an谩lisis conyeva realizar una serie de pasos tales como el entendimiento de los datos, an谩lisis exploratorio, preprocesamiento y las etapas propias del modelo de Machine Learning. Se disponen de datos hist贸ricos de pacientes con la duraci贸n en d铆as de su estad铆a y para el an谩lisis se considera una hospitalizaci贸n corta de 8 d铆as o menos.

## Objetivo

Construir un modelo de Machine Learning optimizado que permita obtener buenas m茅tricas de accuracy y recall. Se considera 茅sta 煤ltima como prioritaria al querer predecir con mayor exhaustividad las estad铆as largas para el ingreso de pacientes.

## Directorios y archivos del repositorio

- [**Data:**](./Data/) Directorio donde se disponibilizan las fuentes de datos. Un archivo de _hospitalizaciones_train_ que se considera para el desarrollo del modelo y otro _hospitalizaciones_test_ que contiene datos nuevos sobre el cual el modelo debe realizar las predicciones correspondientes y comparado con los resultados reales otorgados por Henry
- [**Notebook Modelo:**](./PI02_Datathon_Hospitalizacion.ipynb) Notebook donde se desarrolla el proyecto de Machine Learning

## ETAPAS DEL PROYECTO

---

### **1) Comprensi贸n de los datos y EDA**

En primer lugar se realiza un estudio de las fuente de datos disponibilizada en archivo `.csv` entendiendo cada una de las variables relativas al registro de cada paciente
Se hace una exploraci贸n de datos utilizando Pandas-Profiling para obtenci贸n de un reporte, pandas, matplotlib y seaborn para exploraci贸n de distribuciones, outliers, etc. Determino algunas observaciones necesarias para la selecci贸n de variables.

### **2) Preparaci贸n de los datos**

En esta etapa realizo el Feature Selection en base a ciertos criterios (correlaci贸n, tree-based selection, criterio propio), la divisi贸n de los datos de entrenamiento (80%) y testeo (20%), y el conjunto de pasos de preprocesamiento de datos en el que incluyo `PipeLines` y `ColumnTransformer` para la unificaci贸n de todos los pasos de preprocesado.

### **3) Modelado**

En base a las variables seleccionadas y los datos preprocesados se seleccionan 5 modelos para entrenar en forma simultanea con los par谩metros por defecto:

- Arbol de desici贸n
- KNN
- Regresi贸n log铆stica
- SVM m茅todo lineal
- RandomForest

Se obtiene una tabla con los scores a considerar (accuracy en train-test y recall)

### **4) Evaluaci贸n y Validaci贸n**

En algunos modelos se genera overfitting (Tree y RandomForest) por la diferencia entre los accuracy de entrenamiento y testeo por lo que se decide entrenar y testear nuevamente los modelos reduciendo la dimensionalidad. Se decide quitar algunas variables que contienen outliers y otras que se seleccionaron previamente por criterio propio pero que no tienen correlaci贸n con el target.
Se general algunas alternativas, de las cuales se elige `DecisionTreeClasifier()` con la m铆nima cantidad de variables correlacionadas. Luego se valida con Cross validation

### **5) Optimizaci贸n de Hiperpar谩metros**

### **6) Construcci贸n Final del Pipeline**
